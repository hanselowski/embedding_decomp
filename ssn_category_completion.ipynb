{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/word2vec/GoogleNews-vectors-negative300.bin.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d06e41530615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load Google's pre-trained Word2Vec model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/word2vec/GoogleNews-vectors-negative300.bin.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'... model loaded ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdict_low\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vecdec/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vecdec/lib/python3.6/site-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vecdec/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mbinary_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m     \u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mignore_ext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mdecompressed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vecdec/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[0;34m(uri, mode, transport_params)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmart_open_ssh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCHEMES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/word2vec/GoogleNews-vectors-negative300.bin.gz'"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('data/word2vec/GoogleNews-vectors-negative300.bin.gz', binary=True) \n",
    "print('... model loaded ...')\n",
    "dict_low = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/glove/glove.6B.300d.txt' mode='r' encoding='UTF-8'>\n",
      "Done. 400001  words loaded!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "def loadGloveModel(gloveFile):\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    \n",
    "    print(f)\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "\n",
    "model = loadGloveModel('data/glove/glove.6B.300d.txt')\n",
    "\n",
    "dict_low = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello from object.prop\n",
      "Hello from object.prop.prop\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n        \\n\\n\\n\\n\\n>> hello from object.prop\\n>> Hello from object.prop.prop\\n>> None\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class b():\n",
    "    @property\n",
    "    def words(self):\n",
    "        print(\"Hello from object.prop.prop\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class Glove():\n",
    "    \n",
    "    def __init__(self, glove_filename):\n",
    "        self.glove_filename = glove_filename\n",
    "        # self.vocabulary(self, 'asdf')\n",
    "\n",
    "    @property\n",
    "    def vocabulary(self, words):\n",
    "        self.words = words\n",
    "\n",
    "\n",
    "'''\n",
    "class b():\n",
    "    @property\n",
    "    def prop(self):\n",
    "        print(\"Hello from object.prop.prop\")\n",
    "        \n",
    "        \n",
    "class a():\n",
    "    def __init__(self):\n",
    "        self.b = b()\n",
    "    @property\n",
    "    def prop(self):\n",
    "        print(\"hello from object.prop\")\n",
    "        return self.b\n",
    "'''vbbfvg\n",
    "            \n",
    "            \n",
    "x = a()\n",
    "print(x.prop.prop)\n",
    "\n",
    "\n",
    "            \n",
    "'''\n",
    "model = Glove('data/glove/glove.6B.300d.txt')\n",
    "\n",
    "# model.vocabulary('adsf')\n",
    "print(model.vocabulary.words)\n",
    "'''\n",
    "\n",
    "        \n",
    "'''\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">> hello from object.prop\n",
    ">> Hello from object.prop.prop\n",
    ">> None\n",
    "'''\n",
    "        \n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-1e4e80d8af11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/glove/glove.6B.300d.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-1e4e80d8af11>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, glove_filename)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_to_embedding_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Glove:\n",
    "    \n",
    "    def __init__(self, glove_filename):\n",
    "        \n",
    "        \n",
    "        @property\n",
    "        def vocabulary(self, words):\n",
    "            self.words = words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        word_to_embedding_dict = self.load_embedding_from_disks(glove_filename)\n",
    "        \n",
    "        words = word_to_embedding_dict.keys()\n",
    "        for w in words:\n",
    "            self.w = word_to_embedding_dict[w]\n",
    "            \n",
    "        self.vocabulary(words)\n",
    "        \n",
    "        \n",
    "\n",
    "    def load_embedding_from_disks(self, glove_filename, with_indexes=False):\n",
    "        \"\"\"\n",
    "        Read a GloVe txt file. If `with_indexes=True`, we return a tuple of two dictionnaries\n",
    "        `(word_to_index_dict, index_to_embedding_array)`, otherwise we return only a direct \n",
    "        `word_to_embedding_dict` dictionnary mapping from a string to a numpy array.\n",
    "        \"\"\"\n",
    "        if with_indexes:\n",
    "            word_to_index_dict = dict()\n",
    "            index_to_embedding_array = []\n",
    "        else:\n",
    "            word_to_embedding_dict = dict()\n",
    "            \n",
    "            \n",
    "        with open(glove_filename, 'r') as glove_file:\n",
    "            for (i, line) in enumerate(glove_file):\n",
    "\n",
    "                split = line.split(' ')\n",
    "\n",
    "                word = split[0]\n",
    "\n",
    "                representation = split[1:]\n",
    "                representation = np.array(\n",
    "                    [float(val) for val in representation]\n",
    "                )\n",
    "\n",
    "                if with_indexes:\n",
    "                    word_to_index_dict[word] = i\n",
    "                    index_to_embedding_array.append(representation)\n",
    "                else:\n",
    "                    word_to_embedding_dict[word] = representation\n",
    "        _WORD_NOT_FOUND = [0.0]* len(representation)  # Empty representation for unknown words.\n",
    "        if with_indexes:\n",
    "            _LAST_INDEX = i + 1\n",
    "            word_to_index_dict = defaultdict(lambda: _LAST_INDEX, word_to_index_dict)\n",
    "            index_to_embedding_array = np.array(index_to_embedding_array + [_WORD_NOT_FOUND])\n",
    "            return word_to_index_dict, index_to_embedding_array\n",
    "        else:\n",
    "            word_to_embedding_dict = defaultdict(lambda: _WORD_NOT_FOUND)\n",
    "            return word_to_embedding_dict\n",
    "    \n",
    "    \n",
    "\n",
    "model = Glove('data/glove/glove.6B.300d.txt')\n",
    "\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model['the'])\n",
    "\n",
    "print(model.vocabulary.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'word_analogy_tool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-510b3660353d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mword_analogy_tool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_SG_GoogleNews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_GloVe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_FastText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_GloVe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wiki-6B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# model = fetch_SG_GoogleNews(normalize=False, lower=False, clean_words=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model = fetch_FastText(lang=\"en\", normalize=False, lower=False, clean_words=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'word_analogy_tool'"
     ]
    }
   ],
   "source": [
    "from word_analogy_tool.web.embeddings import fetch_SG_GoogleNews, fetch_GloVe, fetch_FastText\n",
    "\n",
    "model = fetch_GloVe(corpus=\"wiki-6B\", dim=300)\n",
    "# model = fetch_SG_GoogleNews(normalize=False, lower=False, clean_words=False)\n",
    "# model = fetch_FastText(lang=\"en\", normalize=False, lower=False, clean_words=False)\n",
    "dict_low = True\n",
    "\n",
    "print('... model loaded ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded, skipping\n",
      "... model loaded ...\n"
     ]
    }
   ],
   "source": [
    "from word_analogy_tool.web.embeddings import fetch_SG_GoogleNews, fetch_GloVe, fetch_FastText\n",
    "\n",
    "model = fetch_GloVe(corpus=\"wiki-6B\", dim=300)\n",
    "# model = fetch_SG_GoogleNews(normalize=False, lower=False, clean_words=False)\n",
    "# model = fetch_FastText(lang=\"en\", normalize=False, lower=False, clean_words=False)\n",
    "dict_low = True\n",
    "\n",
    "print('... model loaded ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded, skipping\n",
      "... model loaded ...\n"
     ]
    }
   ],
   "source": [
    "from word_analogy_tool.web.embeddings import fetch_SG_GoogleNews, fetch_GloVe, fetch_FastText\n",
    "\n",
    "# model = fetch_GloVe(corpus=\"wiki-6B\", dim=300)\n",
    "# model = fetch_SG_GoogleNews(normalize=False, lower=False, clean_words=False)\n",
    "model = fetch_FastText(lang=\"en\", normalize=False, lower=False, clean_words=False)\n",
    "dict_low = True \n",
    "\n",
    "print('... model loaded ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "from utils.methods import length, unit, cosine, find_vecs, sort_disct, find_sim_cos, hyper_test, find_insts\n",
    "from utils.tree import Tree\n",
    "from random import shuffle\n",
    "from utils.corpuscont import retrieve_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'index2word'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-257418192eac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcorp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosed_cat_corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'index2word'"
     ]
    }
   ],
   "source": [
    "from utils.corpuscont import retrieve_corpus\n",
    "\n",
    "\n",
    "# load corpus \n",
    "# path1 = \"/home/hanselowski/jupiter_projects/vecSpace_decomp/datasets/googe_cat_corpus.txt\"\n",
    "# path2 = \"/home/hanselowski/jupiter_projects/vecSpace_decomp/datasets/wordnet_cat_corpus.txt\"\n",
    "path3 = \"datasets/closed_cat_corpus.txt\"\n",
    "\n",
    "# googe_cat_corpus = retrieve_corpus(path1, dict_low)\n",
    "# wordnet_cat_corpus = retrieve_corpus(path2, dict_low)\n",
    "closed_cat_corpus = retrieve_corpus(path3, dict_low)\n",
    "\n",
    "corp = closed_cat_corpus\n",
    "\n",
    "print(model.index2word[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'vocabulary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8e3e44320df5>\u001b[0m in \u001b[0;36mfind_insts\u001b[0;34m(model, source, normalized)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'index2word'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8e3e44320df5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mh_mail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_upper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0minstances_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_insts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_mail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0minstances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances_all\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstances_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# remove duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-8e3e44320df5>\u001b[0m in \u001b[0;36mfind_insts\u001b[0;34m(model, source, normalized)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'vocabulary'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import operator\n",
    "from utils.methods import length, unit, cosine, find_vecs, sort_disct\n",
    "\n",
    "def find_vecs_norm(lst, model):\n",
    "    # print('support vectors:')\n",
    "    sup_vecs = []\n",
    "    for w in lst: \n",
    "        # sup_vecs.append(model[w])\n",
    "        sup_vecs.append(unit(model[w]))\n",
    "        #print(w)\n",
    "    # print('')\n",
    "    return sup_vecs\n",
    "\n",
    "\n",
    "class Tree:\n",
    "    \"\"\"Tree class\"\"\"\n",
    "        \n",
    "    def __init__(self, model, word_lst, vec_lst, normalize = False):\n",
    "        if vec_lst == None:\n",
    "            if normalize == True:\n",
    "                self.vec_lst = find_vecs_norm(word_lst, model)\n",
    "            else:\n",
    "                self.vec_lst = find_vecs(word_lst, model)\n",
    "            self.word_lst = word_lst\n",
    "        else:\n",
    "            self.vec_lst = vec_lst\n",
    "            self.word_lst = word_lst\n",
    "        \n",
    "        self.model = model\n",
    "        self.root()\n",
    "        # self.root_unit()\n",
    "        # self.find_branches()\n",
    "        \n",
    "    def root(self):\n",
    "        v = self.model['dummy']\n",
    "        H = [0]*v.shape[0]\n",
    "        for vec in self.vec_lst:\n",
    "            H = H + vec\n",
    "        h_u = unit(H)\n",
    "\n",
    "        sup_vec_lens = {}\n",
    "        indzs = range(len(self.word_lst))\n",
    "        for i in indzs: \n",
    "            w = self.word_lst[i]\n",
    "            v = self.vec_lst[i]\n",
    "            v_len = length(v)\n",
    "            cos = cosine(v, H)\n",
    "            h_len = v_len*cos\n",
    "            sup_vec_lens[w] = h_len\n",
    "        self.sup_vec_sort = sort_disct(sup_vec_lens)\n",
    "        self.len = list(self.sup_vec_sort.values())[0]\n",
    "        self.root = self.len * h_u\n",
    "        \n",
    "    def root_unit(self):\n",
    "        v = self.model['dummy']\n",
    "        H = [0]*v.shape[0]\n",
    "        for vec in self.vec_lst:\n",
    "            H = H + unit(vec)\n",
    "        h_u = unit(H)\n",
    "\n",
    "        sup_vec_lens = {}\n",
    "        indzs = range(len(self.word_lst))\n",
    "        for i in indzs: \n",
    "            w = self.word_lst[i]\n",
    "            v = self.vec_lst[i]\n",
    "            v_len = length(v)\n",
    "            cos = cosine(v, H)\n",
    "            h_len = v_len*cos\n",
    "            sup_vec_lens[w] = h_len\n",
    "        self.sup_vec_sort = sort_disct(sup_vec_lens)\n",
    "        self.len = list(self.sup_vec_sort.values())[0]\n",
    "        self.root = self.len * h_u\n",
    "        \n",
    "    def subvec_properties(self):\n",
    "        output = 'sup. vec. order: '\n",
    "        for key in self.sup_vec_sort.keys():\n",
    "            val = sup_vec_sort[key]\n",
    "            output = output + ' ' + key + ' ' + str(val) + '; '\n",
    "        # print(output)\n",
    "        \n",
    "    def hyper_test(self, v, h):\n",
    "        cos = cosine(v, h)\n",
    "        thresh = np.linalg.norm(h)\n",
    "        v_proj = np.linalg.norm(v)*cos\n",
    "        allowance = 0.0000000001 # allowance to include support vectors \n",
    "        instance = 0\n",
    "        if thresh - allowance < v_proj:\n",
    "            instance = 1\n",
    "        return instance\n",
    "    \n",
    "    def find_insts(self):\n",
    "        # print('instances of the root:')\n",
    "        words = []\n",
    "        for i in range(11000):\n",
    "            word = self.model.index2word[i]\n",
    "            instance = self.model[word]\n",
    "            sub_inst = self.hyper_test(instance, self.root)\n",
    "            if sub_inst == 1:\n",
    "                words.append(word)\n",
    "        len_dict = {}\n",
    "        for w in words:\n",
    "            w_vec = self.model[w]\n",
    "            inst_len = length(w_vec)\n",
    "            cos = cosine(self.root, w_vec)\n",
    "            inst_len_root = cos * inst_len\n",
    "            len_dict[w] = inst_len_root\n",
    "        sorted_keys = sorted(len_dict.items(), key=operator.itemgetter(1))\n",
    "        reversed_keys = reversed(sorted_keys)\n",
    "        cnt = 0\n",
    "        for k in reversed_keys:\n",
    "            # print(k)\n",
    "            if cnt > 50:\n",
    "                break\n",
    "            cnt += 1\n",
    "        # print('')\n",
    "    \n",
    "def find_insts(model, source, normalized = False):\n",
    "    # print('instances of the source:')\n",
    "    words = []\n",
    "    voc_size = 50000 # here change vocabulary size\n",
    "    try: # handling differenence word2vec and other embeddings\n",
    "        for i in range(voc_size):\n",
    "            word = model.index2word[i]\n",
    "            if normalized:\n",
    "                instance = unit(model[word])\n",
    "            else:\n",
    "                instance = model[word]\n",
    "            sub_inst = hyper_test(instance, source)\n",
    "            if sub_inst == 1:\n",
    "                words.append(word)\n",
    "    except:\n",
    "        vocabulary = model.vocabulary.words\n",
    "        for i in range(voc_size):\n",
    "            if normalized:\n",
    "                instance = unit(model[vocabulary[i]])\n",
    "            else:\n",
    "                instance = model[vocabulary[i]]\n",
    "            \n",
    "            sub_inst = hyper_test(instance, source)\n",
    "            if sub_inst == 1:\n",
    "                words.append(vocabulary[i]) \n",
    "                    \n",
    "    len_dict = {}\n",
    "    for w in words:\n",
    "        w_vec = model[w]\n",
    "        inst_len = length(w_vec)\n",
    "        cos = cosine(source, w_vec)\n",
    "        inst_len_trunk = cos * inst_len\n",
    "        len_dict[w] = inst_len_trunk\n",
    "    sorted_keys = sorted(len_dict.items(), key=operator.itemgetter(1))\n",
    "    reversed_keys = reversed(sorted_keys)\n",
    "    \n",
    "    cnt = 0\n",
    "    lst_out = []\n",
    "    for k in reversed_keys:\n",
    "        # print(k)\n",
    "        lst_out.append(k[0].lower())\n",
    "        if cnt > 1000:\n",
    "            break\n",
    "        cnt += 1\n",
    "    # print('')\n",
    "    return lst_out\n",
    "\n",
    "\n",
    "##########################################################################################################\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "# closed_cats\n",
    "# cat_set\n",
    "normalization = True\n",
    "cats = corp\n",
    "# inst_pp = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "# itter = 5\n",
    "\n",
    "inst_pp = [0.1]\n",
    "itter = 1\n",
    "\n",
    "for pp in inst_pp:\n",
    "    precision, recall = 0.0, 0.0 \n",
    "    for cat_upper in cats:\n",
    "        cat = []\n",
    "        [cat.append(t.lower()) for t in cat_upper]\n",
    "        percent = pp\n",
    "        examples = int(round(len(cat)*percent))\n",
    "        # print('number of examples: ',examples)\n",
    "        # print('examples: ', cat[:examples])\n",
    "        prec, rec, f1 = 0.0, 0.0, 0.0\n",
    "        for i in range(itter):\n",
    "            if dict_low:\n",
    "                shuffle(cat)\n",
    "                h_mail = Tree(model, cat[:examples], None, normalization)\n",
    "            else:    \n",
    "                shuffle(cat_upper)\n",
    "                h_mail = Tree(model, cat_upper[:examples], None, normalization)\n",
    "\n",
    "            instances_all = find_insts(model, h_mail.root, normalization)\n",
    "            instances = []\n",
    "            [instances.append(el) for i, el in enumerate(instances_all) if el not in instances_all[:i]] # remove duplicates\n",
    "            hit, mis = 0, 0\n",
    "            if not len(instances) == 0:\n",
    "                for ins in instances:\n",
    "                    # print(ins)\n",
    "                    if ins in cat:\n",
    "                        hit += 1\n",
    "                    else:\n",
    "                        mis += 1\n",
    "                prec_tmp = hit/(hit+mis)\n",
    "            else:\n",
    "                prec_tmp = 0.0\n",
    "            rec_tmp = hit/len(cat)\n",
    "            rec += rec_tmp\n",
    "            prec += prec_tmp\n",
    "        \n",
    "        print('exaple prediction: ', instances)\n",
    "        print('recall   : ', rec/itter)\n",
    "        print('precision: ', prec/itter)\n",
    "        if rec+prec == 0.0:\n",
    "            print('f1: ', 0.0)\n",
    "        else:\n",
    "            print('f1: ', 2*rec*prec/(rec+prec)/itter)\n",
    "        print('')\n",
    "        \n",
    "        recall += rec/itter\n",
    "        precision += prec/itter\n",
    "    print('pp: ', pp)\n",
    "    print('Overall results:')\n",
    "    print('recall   : ', recall/len(cats))\n",
    "    print('precision: ', precision/len(cats))\n",
    "    print('F1: ', round(2*recall*precision/(recall+precision)/len(cats),3) )\n",
    "    print(' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net corpus  # ----------------\n",
    "\n",
    "# SSN skip voc 50000\n",
    "\n",
    "\n",
    "# SSN glove voc 50000\n",
    "0.151\n",
    "0.327\n",
    "0.371\n",
    "0.275\n",
    "0.191\n",
    "\n",
    "# SSN fast voc 50000\n",
    "0.154\n",
    "0.324\n",
    "0.348\n",
    "0.221\n",
    "0.169\n",
    "\n",
    "# google corpus # ----------------\n",
    "\n",
    "# SSN skip voc 50000\n",
    "0.273\n",
    "0.414\n",
    "0.366\n",
    "0.294\n",
    "0.259\n",
    "\n",
    "# SSN glove voc 50000 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "0.282\n",
    "0.406\n",
    "0.329\n",
    "0.305\n",
    "0.255\n",
    "\n",
    "# SSN fast voc 50000\n",
    "0.285\n",
    "0.370 \n",
    "0.310\n",
    "0.274\n",
    "0.224\n",
    "\n",
    "\n",
    "\n",
    "# closed cat corpus 13 # ---------------- \n",
    "\n",
    "# SSN fast voc 50000\n",
    "0.3422135106883161\n",
    "0.48876016403508277\n",
    "0.6304522670733148\n",
    "0.6944047148092274\n",
    "0.6641981046083095\n",
    "\n",
    "# SSN glove voc 50000 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "0.34938909841411925\n",
    "0.49472731007783705\n",
    "0.6466469286132784\n",
    "0.6783054491163155\n",
    "0.6553992438755661\n",
    "\n",
    "# SSN skipp voc 50000\n",
    "0.3263556988248189\n",
    "0.47639604516075934\n",
    "0.6453199281370341\n",
    "0.6972205742719733\n",
    "0.7173109596216855\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "# SSN fast voc 100000\n",
    "0.344\n",
    "0.523\n",
    "0.642\n",
    "0.658\n",
    "0.671\n",
    "\n",
    "# SSN glove voc 30000\n",
    "0.3240706009943443\n",
    "0.48777114807377375\n",
    "0.6446169011395081\n",
    "0.666422153215809\n",
    "0.6567388002927008\n",
    "\n",
    "# SSN skipp voc 30000\n",
    "0.3090973225253375\n",
    "0.4631138826398873\n",
    "0.6253693948442005\n",
    "0.7084637611749104\n",
    "0.7065081695884508\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################################################\n",
    "# word net corpus  # ----------------\n",
    "\n",
    "# SSN fasttext voc 100000\n",
    "0.17361511286967993\n",
    "0.3591332971723623\n",
    "0.31269320295423503\n",
    "\n",
    "# SSN glove voc 30000\n",
    "0.12954411937717245\n",
    "0.3057916518007425\n",
    "0.3697948510662949\n",
    "0.26839507660387046\n",
    "0.17727540535368236\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# closed cat corpus # ---------------- \n",
    "\n",
    "# SSN skip voc 50000\n",
    "\n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.07829365079365079\n",
    "precision:  0.7\n",
    "F1:  0.1408351603528272\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.1684920634920635\n",
    "precision:  0.7501226053639847\n",
    "F1:  0.2751745861128341\n",
    "    \n",
    "    \n",
    "    \n",
    "# SSN fasttext voc 50000\n",
    "\n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.11376984126984127\n",
    "precision:  1.0\n",
    "F1:  0.20429686108240994\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.21357142857142858\n",
    "precision:  0.9613636363636363\n",
    "F1:  0.34949983419918207\n",
    " \n",
    "pp:  0.3\n",
    "Overall results:\n",
    "recall   :  0.43034920634920637\n",
    "precision:  0.8780800316890159\n",
    "F1:  0.5776102119439418\n",
    " \n",
    "pp:  0.4\n",
    "Overall results:\n",
    "recall   :  0.6193650793650793\n",
    "precision:  0.7565395268392697\n",
    "F1:  0.6811143184937217\n",
    " \n",
    "pp:  0.5\n",
    "Overall results:\n",
    "recall   :  0.7134047619047619\n",
    "precision:  0.7185769962086797\n",
    "F1:  0.7159815381529198\n",
    "    \n",
    "\n",
    "\n",
    "# SSN glove voc 30000\n",
    "\n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.11091269841269842\n",
    "precision:  0.9800000000000001\n",
    "F1:  0.19927248917827653\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.2358015873015873\n",
    "precision:  0.9515274453365652\n",
    "F1:  0.37794356206863744\n",
    " \n",
    "pp:  0.3\n",
    "Overall results:\n",
    "recall   :  0.4837539682539682\n",
    "precision:  0.888290175650226\n",
    "F1:  0.6263849444509082\n",
    " \n",
    "pp:  0.4\n",
    "Overall results:\n",
    "recall   :  0.6472301587301587\n",
    "precision:  0.6987217680402025\n",
    "F1:  0.6719910151947573\n",
    " \n",
    "pp:  0.5\n",
    "Overall results:\n",
    "recall   :  0.7778253968253969\n",
    "precision:  0.5770412705027217\n",
    "F1:  0.6625557570156271\n",
    "    \n",
    "    \n",
    "# SSN glove voc 50000\n",
    "\n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.11281746031746032\n",
    "precision:  1.0\n",
    "F1:  0.20276004707057022\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.22753968253968254\n",
    "precision:  0.9656860484641815\n",
    "F1:  0.36829895834659765\n",
    " \n",
    "pp:  0.3\n",
    "Overall results:\n",
    "recall   :  0.49215873015873013\n",
    "precision:  0.8327850188667801\n",
    "F1:  0.6186865180988106\n",
    " \n",
    "pp:  0.4\n",
    "Overall results:\n",
    "recall   :  0.6877539682539682\n",
    "precision:  0.658062854388573\n",
    "F1:  0.672580891919025\n",
    " \n",
    "pp:  0.5\n",
    "Overall results:\n",
    "recall   :  0.7846825396825398\n",
    "precision:  0.5920982080812093\n",
    "F1:  0.674921008901803\n",
    "    \n",
    "    \n",
    "    \n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.11376984126984127\n",
    "precision:  1.0\n",
    "F1:  0.20429686108240994\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.21725396825396825\n",
    "precision:  0.9692629551820728\n",
    "F1:  0.35494853741329646\n",
    " \n",
    "pp:  0.3\n",
    "Overall results:\n",
    "recall   :  0.4900158730158729\n",
    "precision:  0.8556966228931795\n",
    "F1:  0.6231716343251873\n",
    " \n",
    "pp:  0.4\n",
    "Overall results:\n",
    "recall   :  0.6786587301587301\n",
    "precision:  0.7022566563174661\n",
    "F1:  0.690256065345308\n",
    " \n",
    "pp:  0.5\n",
    "Overall results:\n",
    "recall   :  0.7585873015873016\n",
    "precision:  0.6700359544950266\n",
    "F1:  0.7115672582297138\n",
    "    \n",
    "    \n",
    "# SSN glove voc 50000\n",
    "0.20429686108240994\n",
    "0.35494853741329646\n",
    "0.6231716343251873\n",
    "\n",
    "\n",
    "# SSN glove voc 30000\n",
    "0.19927248917827653\n",
    "0.35503086327200384\n",
    "0.5736006182980313\n",
    "0.6756309445676015\n",
    "0.6507915143087214\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# google # ---------------- \n",
    "\n",
    "# SSN glove voc 50000\n",
    "F1:  0.27014276546701016\n",
    "F1:  0.4622771054228404\n",
    "F1:  0.5081869227270572    \n",
    "F1:  0.45253498073190607    \n",
    "F1:  0.38422126735754036\n",
    "    \n",
    "    \n",
    "# joint corpus # ---------------- \n",
    "\n",
    "# SSN glove voc 50000\n",
    "F1:  0.24179755519149676\n",
    "F1:  0.43493210908478386\n",
    "F1:  0.4241011399997128\n",
    "F1:  0.41647410771735893\n",
    "F1:  0.32647512329906436\n",
    "\n",
    "\n",
    "# SSN fasttext voc 50000\n",
    "F1:  0.22590866503887777\n",
    "F1:  0.3960121480929155\n",
    "F1:  0.4108976822714649\n",
    "F1:  0.3723876211490508\n",
    "F1:  0.30812075542002776    \n",
    "    \n",
    "    \n",
    "# SSN fasttext voc 30000\n",
    "F1:  0.2135440977364141\n",
    "F1:  0.39243097431200835\n",
    "F1:  0.43610195122479445\n",
    "F1:  0.3976523630881609\n",
    "F1:  0.35104009540817904\n",
    "    \n",
    "    \n",
    "# SSN glove voc 30000\n",
    "0.20229598928941672\n",
    "0.4142565124910447\n",
    "0.4327208380903787\n",
    "0.38678675233219334\n",
    "0.31573027759877204\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# google cat corpus # ---------------- \n",
    "\n",
    "# SSN glove voc 30000\n",
    "0.2595929858878393\n",
    "0.38020870099980847\n",
    "\n",
    "\n",
    "# closed set corpus # ----------------\n",
    "\n",
    "# SSN glove voc 30000\n",
    "0.19927248917827653\n",
    "0.35503086327200384\n",
    "0.5736006182980313\n",
    "0.6756309445676015\n",
    "0.6507915143087214\n",
    "\n",
    "\n",
    "# baseline  # ----------------\n",
    "\n",
    ".182             \n",
    ".333              \n",
    ".461          \n",
    ".571           \n",
    ".666    \n",
    "\n",
    "\n",
    "#################################################################\n",
    "# old\n",
    "\n",
    "# SSN fast text 30000\n",
    "0.31047904159063033\n",
    "0.4925452038119263\n",
    "0.6253954988622927\n",
    "0.6852487357692942\n",
    "0.6930315079725218\n",
    "\n",
    "# SSN glove voc 30000\n",
    "0.3367852958808458\n",
    "0.48726314217144384\n",
    "0.6464009897935541 \n",
    "0.6529612957237936\n",
    "0.6386135895783802\n",
    "\n",
    "# SSN skip voc 30000\n",
    "0.3081217544115887\n",
    "0.43822125075132323\n",
    "0.5936353735433153\n",
    "0.655352746745947\n",
    "0.6882628999892039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nGaussianNB \\n    0.5 = 0.5565598629669128\\n    0.4 = 0.536749645991096\\n    0.3 = 0.46503256639827845\\n    0.2 = 0.3895454920136168\\n    0.1 = 0.2766768204583401\\n    \\n    \\nsvm.SVC(kernel='linear', class_weight='balanced')\\n    0.5 = 0.5206721647159487\\n    0.4 = 0.5224660031607513\\n    0.3 = 0.5252691830880086\\n    0.2 = 0.48871205107176247\\n    0.1 = 0.39314626096220723\\n    \\n    \\nno european and asian coutnires\\n\\nskip \\npp:  0.1\\nOverall results:\\nrecall   :  0.19144983369121304\\nprecision:  0.8654576812304122\\nF1:  0.31354063964741913\\n \\npp:  0.2\\nOverall results:\\nrecall   :  0.29130579641228727\\nprecision:  0.8152598965544744\\nF1:  0.42923783912381547\\n \\npp:  0.3\\nOverall results:\\nrecall   :  0.4698102123254254\\nprecision:  0.7806464495678017\\nF1:  0.5865947783704232\\n \\npp:  0.4\\nOverall results:\\nrecall   :  0.6181656623745873\\nprecision:  0.732269742375104\\nF1:  0.6703971307921651\\n \\npp:  0.5\\nOverall results:\\nrecall   :  0.6892195560806109\\nprecision:  0.701674416037214\\nF1:  0.6953912220899657\\n \\nglove \\n\\npp:  0.1\\nOverall results:\\nrecall   :  0.20402014032845678\\nprecision:  0.9246294057812564\\nF1:  0.3342809497767202\\n \\npp:  0.2\\nOverall results:\\nrecall   :  0.3178231257135922\\nprecision:  0.8591956472165898\\nF1:  0.4640066114121146\\n \\npp:  0.3\\nOverall results:\\nrecall   :  0.5390924778399424\\nprecision:  0.7227074684319036\\nF1:  0.6175403019496546\\n \\npp:  0.4\\nOverall results:\\nrecall   :  0.6559037638043723\\nprecision:  0.6203618902816412\\nF1:  0.6376379360422729\\n \\npp:  0.5\\nOverall results:\\nrecall   :  0.7456095656653466\\nprecision:  0.5591996722862477\\nF1:  0.6390890141582843\\n\\n\\nfast text\\npp:  0.1\\nOverall results:\\nrecall   :  0.1837018007910503\\nprecision:  0.9042179535861271\\nF1:  0.30536529135177637\\n \\npp:  0.2\\nOverall results:\\nrecall   :  0.3159257690697853\\nprecision:  0.8261617040938631\\nF1:  0.4570679179570317\\n\\n\\n\\n\\n\\n \\n \\n\\n\\nno world countries\\n\\npp:  0.1\\nOverall results:\\nrecall   :  0.17223311100824867\\nprecision:  0.9239019832141331\\nF1:  0.29034106046672675\\n \\npp:  0.2\\nOverall results:\\nrecall   :  0.3393388886380048\\nprecision:  0.8648948003942671\\nF1:  0.4874343626616717\\n \\npp:  0.3\\nOverall results:\\nrecall   :  0.5512830768671104\\nprecision:  0.7307680071064795\\nF1:  0.6284617523742998\\n \\npp:  0.4\\nOverall results:\\nrecall   :  0.6936981936975418\\nprecision:  0.6238426354491959\\nF1:  0.6569185558262861\\n \\npp:  0.5\\nOverall results:\\nrecall   :  0.777291008984576\\nprecision:  0.5105899301710869\\nF1:  0.6163255467702496\\n\\n\\n\\n\\n\\nnew with new states corpus \\n\\npp:  0.1\\nOverall results:\\nrecall   :  0.19817232091025197\\nprecision:  0.9297205760784404\\nF1:  0.3267063474757003\\n \\npp:  0.2\\nOverall results:\\nrecall   :  0.402823149392115\\nprecision:  0.8496603927693337\\nF1:  0.5465347268969795\\n \\npp:  0.3\\nOverall results:\\nrecall   :  0.6039465525534491\\nprecision:  0.7233711528607336\\nF1:  0.6582862749510732\\n \\npp:  0.4\\nOverall results:\\nrecall   :  0.7425417541589956\\nprecision:  0.6099313926346764\\nF1:  0.66973533230924\\n \\npp:  0.5\\nOverall results:\\nrecall   :  0.8166399479192583\\nprecision:  0.5510283575217474\\nF1:  0.6580422568811287\\n\\n\\n------------------------------------------\\n% unnormolized\\n% \\n% 5\\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.3602868576619084\\n% precision:  0.5515516960548889\\n% F1:  0.43585967406118303\\n% \\n% \\n% 10\\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.46330238890401165\\n% precision:  0.5496509261035842\\n% F1:  0.5027962954545113\\n% \\n% \\n% 20\\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.5507189248809937\\n% precision:  0.3178008063129157\\n% F1:  0.4030280766065552\\n% \\n% \\n% 30\\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.5882277878758608\\n% precision:  0.2565712914169673\\n% F1:  0.3572976507242193\\n% \\n% 40\\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.590752200260111\\n% precision:  0.2069664512861328\\n% F1:  0.30653886866081953\\n% \\n% \\n% normlazied\\n% \\n% 5\\n% \\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.3026011111794073\\n% precision:  0.6843597146460421\\n% F1:  0.4196478820222989\\n% \\n% 10\\n% \\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.38723660511226426\\n% precision:  0.7175155540043554\\n% F1:  0.5030056469318236\\n% \\n% 20\\n% \\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.5064911136868541\\n% precision:  0.7297847329681997\\n% F1:  0.5979725045228698\\n% \\n% 30\\n% \\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.5371756919138257\\n% precision:  0.7303570799618432\\n% F1:  0.6190452483403683\\n% \\n% 40\\n% \\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.5376024730059213\\n% precision:  0.7075385461307374\\n% F1:  0.610974124698965\\n\\n\\n\\n% skim gram\\n% \\n% pp:  0.1\\n% Overall results:\\n% recall   :  0.2139434163912866\\n% precision:  0.8587747145655753\\n% F1:  0.342548878484463\\n%  \\n% pp:  0.2\\n% Overall results:\\n% recall   :  0.36664810502396705\\n% precision:  0.7725656965620192\\n% F1:  0.49728988229713866\\n%  \\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.5371756919138257\\n% precision:  0.7303570799618432\\n% F1:  0.6190452483403683\\n%  \\n% pp:  0.4\\n% Overall results:\\n% recall   :  0.6545640126757774\\n% precision:  0.668114324374257\\n% F1:  0.6612697597572229\\n%  \\n% pp:  0.5\\n% Overall results:\\n% recall   :  0.7239228616699206\\n% precision:  0.6177684597250988\\n% F1:  0.6666462010779356\\n% \\n% \\n% \\n% fasttext\\n% \\n% pp:  0.1\\n% Overall results:\\n% recall   :  0.20132378981547341\\n% precision:  0.8963522839971894\\n% F1:  0.3287983461227702\\n%  \\n% pp:  0.2\\n% Overall results:\\n% recall   :  0.38115734374557914\\n% precision:  0.8036405517300882\\n% F1:  0.517072994800847\\n%  \\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.539316963511284\\n% precision:  0.7392777386537452\\n% F1:  0.6236613127320236\\n%  \\n% pp:  0.4\\n% Overall results:\\n% recall   :  0.674782098586561\\n% precision:  0.603862465694362\\n% F1:  0.6373555141777036\\n%  \\n% pp:  0.5\\n% Overall results:\\n% recall   :  0.7445343680209805\\n% precision:  0.5771092409497275\\n% F1:  0.6502171403442186\\n% \\n% glove \\n% pp:  0.1\\n% Overall results:\\n% recall   :  0.21434275225938512\\n% precision:  0.9070460139374455\\n% F1:  0.34674636471100784\\n%  \\n% pp:  0.2\\n% Overall results:\\n% recall   :  0.38428563594019993\\n% precision:  0.8229847727539555\\n% F1:  0.523927737297792\\n%  \\n% pp:  0.3\\n% Overall results:\\n% recall   :  0.5795979280879888\\n% precision:  0.693105797246491\\n% F1:  0.6312901833052511\\n \\n\\nopen cat: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\n\\nskip gram ---------------------------------------------\\nnormalization false 40%\\n\\nvoc 5000\\nrecall   :  0.39377679844449925\\nprecision:  0.43414284068017006\\nF1:  0.41297577637216787\\n\\nvoc 10000\\nrecall   :  0.4861977518034074\\nprecision:  0.4712824542507789\\nF1:  0.47862393033773787\\n\\nvoc 20000\\nrecall   :  0.575065140470104\\nprecision:  0.25154257344709696\\nF1:  0.34999277867386513\\n\\nvoc 30000\\nrecall   :  0.6101971815587137\\nprecision:  0.18314370894651333\\nF1:  0.2817295222188866\\n\\n\\nskip gram\\nnormalization true 40%\\n\\nvoc 5000\\nrecall   :  0.3566569057028429\\nprecision:  0.6174609902915011\\nF1:  0.45214594064055375\\n\\nvoc 10000\\nrecall   :  0.4648313723424092\\nprecision:  0.6278635220467257\\nF1:  0.5341850942936373\\n\\nvoc 20000\\nrecall   :  0.549233574774799\\nprecision:  0.643453820112245\\nF1:  0.5926220790758318\\n\\nvoc 30000\\nOverall results:\\nrecall   :  0.5934301693878117\\nprecision:  0.6576893801941331\\nF1:  0.6239095543244986\\n\\nvoc 40000\\nrecall   :  0.5873399727584193\\nprecision:  0.6378081207346217\\nF1:  0.611534566713994\\n\\n\\n\\npp:  0.1\\nOverall results:\\nrecall   :  0.17854516313870808\\nprecision:  0.7969814427777067\\nF1:  0.29173408671021095\\n \\npp:  0.2\\nOverall results:\\nrecall   :  0.3227162945699517\\nprecision:  0.6826654620834607\\nF1:  0.4382559498349946\\n \\npp:  0.3\\nOverall results:\\nrecall   :  0.46509734905087485\\nprecision:  0.7088581621651995\\nF1:  0.561670436275039\\n \\npp:  0.4\\nOverall results:\\nrecall   :  0.5758031672685056\\nprecision:  0.6386767608293418\\nF1:  0.605612481916121\\n \\npp:  0.5\\nOverall results:\\nrecall   :  0.6531620389381396\\nprecision:  0.597985704613698\\nF1:  0.6243572177535731\\n\\n\\n\\n# glove 10 itter\\npp:  0.1\\nOverall results:\\nrecall   :  0.18712273165458942ä88ä\\nprecision:  0.8446530961882875\\nF1:  0.30637235413762404\\n \\npp:  0.2\\nOverall results:\\nrecall   :  0.34416958434981343\\nprecision:  0.7897873187419957\\nF1:  0.4794199364632797\\n \\npp:  0.3\\nOverall results:\\nrecall   :  0.5239281742200843\\nprecision:  0.7225874508201804\\nF1:  0.6074274822031744\\n \\npp:  0.4\\nOverall results:\\nrecall   :  0.6351207942516855\\nprecision:  0.6328918870962126\\nF1:  0.6340043816923154\\n \\npp:  0.5\\nOverall results:\\nrecall   :  0.7010105390241412\\nprecision:  0.5496698335841971\\nF1:  0.6161835665855383\\n\\n\\n\\n\\n\\nfast text \\n\\npp:  0.1\\nOverall results:\\nrecall   :  0.18738980425903232\\nprecision:  0.8577007174146527\\nF1:  0.30757980522446515\\n \\npp:  0.2\\nOverall results:\\nrecall   :  0.35379448549965203\\nprecision:  0.7973464867107393\\nF1:  0.4901168437938685\\n \\npp:  0.3\\nOverall results:\\nrecall   :  0.5186101008723607\\nprecision:  0.7185558897426921\\nF1:  0.6024257784141392\\n \\npp:  0.4\\nOverall results:\\nrecall   :  0.6326561256625092\\nprecision:  0.6601770871475622\\nF1:  0.6461236825717226\\n \\npp:  0.5\\nOverall results:\\nrecall   :  0.6993360446643467\\nprecision:  0.5638549023848556\\nF1:  0.6243300874179982\\n\\n\\n\\n\\nClosed cat corpus:\\nWord2vec not mormalized: different vocabulary size\\n\\nWord2vec nomalized: differen vocabulary size, precision versus recall\\n\\nFasttext and glove: all have different maxima\\n\\n\\nGoogle analogy corpus: \\nWord2vec, glove, fast text \\n\\nCategories which have a large number of instance a few examples are sufficient to reach high performance \\n\\n\\n\\n\\n\\n\\n# glove\\n# prepare: 40% \\nrecall   :  0.6982288547035649\\nprecision:  0.18628844112160228\\nF1:  0.2941083583165088\\n\\n# prepare: 30% \\nrecall   :  0.6383019834850938\\nprecision:  0.21997874410850024\\nF1:  0.32719566960963553\\n\\n# prepare: 20% \\nrecall   :  0.45640120954019453\\nprecision:  0.3519729693443732\\nF1:  0.3974419102695376\\n\\n# prepare: 10% \\nrecall   :  0.15458288421732633\\nprecision:  0.7415182652404463\\nF1:  0.2558327979158522\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "GaussianNB \n",
    "    0.5 = 0.5565598629669128\n",
    "    0.4 = 0.536749645991096\n",
    "    0.3 = 0.46503256639827845\n",
    "    0.2 = 0.3895454920136168\n",
    "    0.1 = 0.2766768204583401\n",
    "    \n",
    "    \n",
    "svm.SVC(kernel='linear', class_weight='balanced')\n",
    "    0.5 = 0.5206721647159487\n",
    "    0.4 = 0.5224660031607513\n",
    "    0.3 = 0.5252691830880086\n",
    "    0.2 = 0.48871205107176247\n",
    "    0.1 = 0.39314626096220723\n",
    "    \n",
    "    \n",
    "no european and asian coutnires\n",
    "\n",
    "skip first\n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.19144983369121304\n",
    "precision:  0.8654576812304122\n",
    "F1:  0.31354063964741913\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.29130579641228727\n",
    "precision:  0.8152598965544744\n",
    "F1:  0.42923783912381547\n",
    " \n",
    "pp:  0.3\n",
    "Overall results:\n",
    "recall   :  0.4698102123254254\n",
    "precision:  0.7806464495678017\n",
    "F1:  0.5865947783704232\n",
    " \n",
    "pp:  0.4\n",
    "Overall results:\n",
    "recall   :  0.6181656623745873\n",
    "precision:  0.732269742375104\n",
    "F1:  0.6703971307921651\n",
    " \n",
    "pp:  0.5\n",
    "Overall results:\n",
    "recall   :  0.6892195560806109\n",
    "precision:  0.701674416037214\n",
    "F1:  0.6953912220899657\n",
    " \n",
    " \n",
    "skip  second \n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.1846991891363088\n",
    "precision:  0.8784582842201729\n",
    "F1:  0.30522389552189255\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.31009551919795325\n",
    "precision:  0.8176022716352395\n",
    "F1:  0.44965025733150177\n",
    " \n",
    "pp:  0.3\n",
    "Overall results:\n",
    "recall   :  0.4611499206225372\n",
    "precision:  0.793047665334601\n",
    "F1:  0.5831838173087311\n",
    " \n",
    "pp:  0.4\n",
    "Overall results:\n",
    "recall   :  0.6033788855949098\n",
    "precision:  0.7219282131453097\n",
    "F1:  0.6573514035217963\n",
    " \n",
    "pp:  0.5\n",
    "Overall results:\n",
    "recall   :  0.6728362459041972\n",
    "precision:  0.6709601236842248\n",
    "F1:  0.6718968751335124\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "glove \n",
    "\n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.20402014032845678\n",
    "precision:  0.9246294057812564\n",
    "F1:  0.3342809497767202\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.3178231257135922\n",
    "precision:  0.8591956472165898\n",
    "F1:  0.4640066114121146\n",
    " \n",
    "pp:  0.3\n",
    "Overall results:\n",
    "recall   :  0.5390924778399424\n",
    "precision:  0.7227074684319036\n",
    "F1:  0.6175403019496546\n",
    " \n",
    "pp:  0.4\n",
    "Overall results:\n",
    "recall   :  0.6559037638043723\n",
    "precision:  0.6203618902816412\n",
    "F1:  0.6376379360422729\n",
    " \n",
    "pp:  0.5\n",
    "Overall results:\n",
    "recall   :  0.7456095656653466\n",
    "precision:  0.5591996722862477\n",
    "F1:  0.6390890141582843\n",
    "\n",
    "\n",
    "fast text\n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.1837018007910503\n",
    "precision:  0.9042179535861271\n",
    "F1:  0.30536529135177637\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.3159257690697853\n",
    "precision:  0.8261617040938631\n",
    "F1:  0.4570679179570317\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "\n",
    "no world countries\n",
    "\n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.17223311100824867\n",
    "precision:  0.9239019832141331\n",
    "F1:  0.29034106046672675\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.3393388886380048\n",
    "precision:  0.8648948003942671\n",
    "F1:  0.4874343626616717\n",
    " \n",
    "pp:  0.3\n",
    "Overall results:\n",
    "recall   :  0.5512830768671104\n",
    "precision:  0.7307680071064795\n",
    "F1:  0.6284617523742998\n",
    " \n",
    "pp:  0.4\n",
    "Overall results:\n",
    "recall   :  0.6936981936975418\n",
    "precision:  0.6238426354491959\n",
    "F1:  0.6569185558262861\n",
    " \n",
    "pp:  0.5\n",
    "Overall results:\n",
    "recall   :  0.777291008984576\n",
    "precision:  0.5105899301710869\n",
    "F1:  0.6163255467702496\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new with new states corpus \n",
    "\n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.19817232091025197\n",
    "precision:  0.9297205760784404\n",
    "F1:  0.3267063474757003\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.402823149392115\n",
    "precision:  0.8496603927693337\n",
    "F1:  0.5465347268969795\n",
    " \n",
    "pp:  0.3\n",
    "Overall results:\n",
    "recall   :  0.6039465525534491\n",
    "precision:  0.7233711528607336\n",
    "F1:  0.6582862749510732\n",
    " \n",
    "pp:  0.4\n",
    "Overall results:\n",
    "recall   :  0.7425417541589956\n",
    "precision:  0.6099313926346764\n",
    "F1:  0.66973533230924\n",
    " \n",
    "pp:  0.5\n",
    "Overall results:\n",
    "recall   :  0.8166399479192583\n",
    "precision:  0.5510283575217474\n",
    "F1:  0.6580422568811287\n",
    "\n",
    "\n",
    "------------------------------------------\n",
    "% unnormolized\n",
    "% \n",
    "% 5\n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.3602868576619084\n",
    "% precision:  0.5515516960548889\n",
    "% F1:  0.43585967406118303\n",
    "% \n",
    "% \n",
    "% 10\n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.46330238890401165\n",
    "% precision:  0.5496509261035842\n",
    "% F1:  0.5027962954545113\n",
    "% \n",
    "% \n",
    "% 20\n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.5507189248809937\n",
    "% precision:  0.3178008063129157\n",
    "% F1:  0.4030280766065552\n",
    "% \n",
    "% \n",
    "% 30\n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.5882277878758608\n",
    "% precision:  0.2565712914169673\n",
    "% F1:  0.3572976507242193\n",
    "% \n",
    "% 40\n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.590752200260111\n",
    "% precision:  0.2069664512861328\n",
    "% F1:  0.30653886866081953\n",
    "% \n",
    "% \n",
    "% normlazied\n",
    "% \n",
    "% 5\n",
    "% \n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.3026011111794073\n",
    "% precision:  0.6843597146460421\n",
    "% F1:  0.4196478820222989\n",
    "% \n",
    "% 10\n",
    "% \n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.38723660511226426\n",
    "% precision:  0.7175155540043554\n",
    "% F1:  0.5030056469318236\n",
    "% \n",
    "% 20\n",
    "% \n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.5064911136868541\n",
    "% precision:  0.7297847329681997\n",
    "% F1:  0.5979725045228698\n",
    "% \n",
    "% 30\n",
    "% \n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.5371756919138257\n",
    "% precision:  0.7303570799618432\n",
    "% F1:  0.6190452483403683\n",
    "% \n",
    "% 40\n",
    "% \n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.5376024730059213\n",
    "% precision:  0.7075385461307374\n",
    "% F1:  0.610974124698965\n",
    "\n",
    "\n",
    "\n",
    "% skim gram\n",
    "% \n",
    "% pp:  0.1\n",
    "% Overall results:\n",
    "% recall   :  0.2139434163912866\n",
    "% precision:  0.8587747145655753\n",
    "% F1:  0.342548878484463\n",
    "%  \n",
    "% pp:  0.2\n",
    "% Overall results:\n",
    "% recall   :  0.36664810502396705\n",
    "% precision:  0.7725656965620192\n",
    "% F1:  0.49728988229713866\n",
    "%  \n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.5371756919138257\n",
    "% precision:  0.7303570799618432\n",
    "% F1:  0.6190452483403683\n",
    "%  \n",
    "% pp:  0.4\n",
    "% Overall results:\n",
    "% recall   :  0.6545640126757774\n",
    "% precision:  0.668114324374257\n",
    "% F1:  0.6612697597572229\n",
    "%  \n",
    "% pp:  0.5\n",
    "% Overall results:\n",
    "% recall   :  0.7239228616699206\n",
    "% precision:  0.6177684597250988\n",
    "% F1:  0.6666462010779356\n",
    "% \n",
    "% \n",
    "% \n",
    "% fasttext\n",
    "% \n",
    "% pp:  0.1\n",
    "% Overall results:\n",
    "% recall   :  0.20132378981547341\n",
    "% precision:  0.8963522839971894\n",
    "% F1:  0.3287983461227702\n",
    "%  \n",
    "% pp:  0.2\n",
    "% Overall results:\n",
    "% recall   :  0.38115734374557914\n",
    "% precision:  0.8036405517300882\n",
    "% F1:  0.517072994800847\n",
    "%  \n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.539316963511284\n",
    "% precision:  0.7392777386537452\n",
    "% F1:  0.6236613127320236\n",
    "%  \n",
    "% pp:  0.4\n",
    "% Overall results:\n",
    "% recall   :  0.674782098586561\n",
    "% precision:  0.603862465694362\n",
    "% F1:  0.6373555141777036\n",
    "%  \n",
    "% pp:  0.5\n",
    "% Overall results:\n",
    "% recall   :  0.7445343680209805\n",
    "% precision:  0.5771092409497275\n",
    "% F1:  0.6502171403442186\n",
    "% \n",
    "% glove \n",
    "% pp:  0.1\n",
    "% Overall results:\n",
    "% recall   :  0.21434275225938512\n",
    "% precision:  0.9070460139374455\n",
    "% F1:  0.34674636471100784\n",
    "%  \n",
    "% pp:  0.2\n",
    "% Overall results:\n",
    "% recall   :  0.38428563594019993\n",
    "% precision:  0.8229847727539555\n",
    "% F1:  0.523927737297792\n",
    "%  \n",
    "% pp:  0.3\n",
    "% Overall results:\n",
    "% recall   :  0.5795979280879888\n",
    "% precision:  0.693105797246491\n",
    "% F1:  0.6312901833052511\n",
    " \n",
    "\n",
    "open cat: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "skip gram ---------------------------------------------\n",
    "normalization false 40%\n",
    "\n",
    "voc 5000\n",
    "recall   :  0.39377679844449925\n",
    "precision:  0.43414284068017006\n",
    "F1:  0.41297577637216787\n",
    "\n",
    "voc 10000\n",
    "recall   :  0.4861977518034074\n",
    "precision:  0.4712824542507789\n",
    "F1:  0.47862393033773787\n",
    "\n",
    "voc 20000\n",
    "recall   :  0.575065140470104\n",
    "precision:  0.25154257344709696\n",
    "F1:  0.34999277867386513\n",
    "\n",
    "voc 30000\n",
    "recall   :  0.6101971815587137\n",
    "precision:  0.18314370894651333\n",
    "F1:  0.2817295222188866\n",
    "\n",
    "\n",
    "skip gram\n",
    "normalization true 40%\n",
    "\n",
    "voc 5000\n",
    "recall   :  0.3566569057028429\n",
    "precision:  0.6174609902915011\n",
    "F1:  0.45214594064055375\n",
    "\n",
    "voc 10000\n",
    "recall   :  0.4648313723424092\n",
    "precision:  0.6278635220467257\n",
    "F1:  0.5341850942936373\n",
    "\n",
    "voc 20000\n",
    "recall   :  0.549233574774799\n",
    "precision:  0.643453820112245\n",
    "F1:  0.5926220790758318\n",
    "\n",
    "voc 30000\n",
    "Overall results:\n",
    "recall   :  0.5934301693878117\n",
    "precision:  0.6576893801941331\n",
    "F1:  0.6239095543244986\n",
    "\n",
    "voc 40000\n",
    "recall   :  0.5873399727584193\n",
    "precision:  0.6378081207346217\n",
    "F1:  0.611534566713994\n",
    "\n",
    "\n",
    "\n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.17854516313870808\n",
    "precision:  0.7969814427777067\n",
    "F1:  0.29173408671021095\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.3227162945699517\n",
    "precision:  0.6826654620834607\n",
    "F1:  0.4382559498349946\n",
    " \n",
    "pp:  0.3\n",
    "Overall results:\n",
    "recall   :  0.46509734905087485\n",
    "precision:  0.7088581621651995\n",
    "F1:  0.561670436275039\n",
    " \n",
    "pp:  0.4\n",
    "Overall results:\n",
    "recall   :  0.5758031672685056\n",
    "precision:  0.6386767608293418\n",
    "F1:  0.605612481916121\n",
    " \n",
    "pp:  0.5\n",
    "Overall results:\n",
    "recall   :  0.6531620389381396\n",
    "precision:  0.597985704613698\n",
    "F1:  0.6243572177535731\n",
    "\n",
    "\n",
    "\n",
    "# glove 10 itter\n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.18712273165458942ä88ä\n",
    "precision:  0.8446530961882875\n",
    "F1:  0.30637235413762404\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.34416958434981343\n",
    "precision:  0.7897873187419957\n",
    "F1:  0.4794199364632797\n",
    " \n",
    "pp:  0.3\n",
    "Overall results:\n",
    "recall   :  0.5239281742200843\n",
    "precision:  0.7225874508201804\n",
    "F1:  0.6074274822031744\n",
    " \n",
    "pp:  0.4\n",
    "Overall results:\n",
    "recall   :  0.6351207942516855\n",
    "precision:  0.6328918870962126\n",
    "F1:  0.6340043816923154\n",
    " \n",
    "pp:  0.5\n",
    "Overall results:\n",
    "recall   :  0.7010105390241412\n",
    "precision:  0.5496698335841971\n",
    "F1:  0.6161835665855383\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fast text \n",
    "\n",
    "pp:  0.1\n",
    "Overall results:\n",
    "recall   :  0.18738980425903232\n",
    "precision:  0.8577007174146527\n",
    "F1:  0.30757980522446515\n",
    " \n",
    "pp:  0.2\n",
    "Overall results:\n",
    "recall   :  0.35379448549965203\n",
    "precision:  0.7973464867107393\n",
    "F1:  0.4901168437938685\n",
    " \n",
    "pp:  0.3\n",
    "Overall results:\n",
    "recall   :  0.5186101008723607\n",
    "precision:  0.7185558897426921\n",
    "F1:  0.6024257784141392\n",
    " \n",
    "pp:  0.4\n",
    "Overall results:\n",
    "recall   :  0.6326561256625092\n",
    "precision:  0.6601770871475622\n",
    "F1:  0.6461236825717226\n",
    " \n",
    "pp:  0.5\n",
    "Overall results:\n",
    "recall   :  0.6993360446643467\n",
    "precision:  0.5638549023848556\n",
    "F1:  0.6243300874179982\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Closed cat corpus:\n",
    "Word2vec not mormalized: different vocabulary size\n",
    "\n",
    "Word2vec nomalized: differen vocabulary size, precision versus recall\n",
    "\n",
    "Fasttext and glove: all have different maxima\n",
    "\n",
    "\n",
    "Google analogy corpus: \n",
    "Word2vec, glove, fast text \n",
    "\n",
    "Categories which have a large number of instance a few examples are sufficient to reach high performance \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# glove\n",
    "# prepare: 40% \n",
    "recall   :  0.6982288547035649\n",
    "precision:  0.18628844112160228\n",
    "F1:  0.2941083583165088\n",
    "\n",
    "# prepare: 30% \n",
    "recall   :  0.6383019834850938\n",
    "precision:  0.21997874410850024\n",
    "F1:  0.32719566960963553\n",
    "\n",
    "# prepare: 20% \n",
    "recall   :  0.45640120954019453\n",
    "precision:  0.3519729693443732\n",
    "F1:  0.3974419102695376\n",
    "\n",
    "# prepare: 10% \n",
    "recall   :  0.15458288421732633\n",
    "precision:  0.7415182652404463\n",
    "F1:  0.2558327979158522\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VfWd//HXhxASlrAEgYAB2RMRkCpgFRfqhlrr0lZ/ta1jh1qmTutoXartb1odZ/qrWluX1tYyU0daW5darVZbRVGKClpBwS1hU5awhiUm7CT5/P44J+ESstyEuyXn/Xw87uPec8+553zvyc15n+/3exZzd0REJLo6pbsAIiKSXgoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBZDQzczMbme5ytCeZss7MbJWZnZnuckjLFAQRY2Ynm9l8M/vEzLaZ2etmNind5RKR9Omc7gJI6phZT+BZ4CrgcaALcAqwN8HLyXL3mkTOM5XMzABz99p0lyWKzKyzu1enuxxRohpBtIwGcPdH3L3G3Xe7+2x3f7duAjP7hpmVmFmVmX1oZseF7x9tZnPNrMLMPjCzC2I+85CZ/crM/mpmO4HPmFmOmd1lZmvMbJOZPWBmXcPpjzCzZ8N5bTOzV82sud/ieWb2kZltMbOfmFmncP7bzGxcTDn6m9luM+vXcAZmlmVmPw3n8bGZfTtsQukcjp9rZj8ys9eBXcBwMxtkZs+Ey1lhZt9o8J3/K2Z4qpmVxQyvMrPvhetwu5n9r5nlNvblzGyEmb1sZlvD8v3ezHo3mNcNZvZuWJN7LHZeZnajmW0ws/VmNr2Z9YiZDTOzeeHf9yUzu9/MHo4Z/+mwxlhhZkvMbGrMuLlm9p9hLbLKzGab2REx4y83s9Xh9/i/DZbbycxuNrOV4fjHzSw/HDc0/Ft83czWAC839x0kCdxdj4g8gJ7AVmAWcC7Qp8H4S4B1wCTAgJHAUUA2sAL4PkEt4nSgCigKP/cQ8AkwhWDnIhe4B3gGyAfygL8APw6n/zHwQDjfbIJaiTVRZgdeCeczBFgGXBmO+yVwR8y01wB/aWI+3wQ+BAqBPsBL4bw7h+PnAmuAYwhqytnA38Nl5AITgHLgjJjv/F8x858KlMUMrwLeBwaHZX89dvoGZRsJnAXkAP2AecA9Deb1D2BQOK8S4JvhuHOATcBYoDvwh/B7jWxiWQuAu8K/48lAJfBwOO7I8PdxXvh3PCsc7hezjlYS7FB0DYdvD8eNAXYAp4bf42dANXBmOP5a4I1w/ecAvwYeCccNDcv82/A7dE33/0rUHmkvgB4p/oPD0eFGrCz8R30GGBCOewG4ppHPnAJsBDrFvPcIcGv4+iHgtzHjDNgJjIh570Tg4/D1bcDTTW2sGizbgXNihv8VmBO+PgFYW1cuYCFwaRPzeRn4l5jhMzk0CG6LGT8YqAHyYt77MfBQzHduKQi+GTN8HrAyzr/RRcA7Deb11ZjhO4EHwtcP1m2Mw+HRNBEEBEFaDXSLee9hDgTBTcDvGnzmBeCKmHX07w3+Fs+Hr38IPBozrjuwjwNBUEIYouHwQGA/QegODcs8PN3/H1F9qGkoYty9xN2/5u6FBHuRgwj23iHY+K1s5GODgLV+cJv5aoI9yDprY173A7oBi8Imhgrg+fB9gJ8Q1DBmh00+N7dQ7Nh5rw7Lg7u/SRA4p5lZMcGe9TNNzGNQg/msbWSa2PcGAdvcvarBso8kfo2Wu6GwSetRM1tnZpUEG+cjGky2Meb1LqBHTDkbLqcpdd9pVxNlPAq4pO5vFv7dTibYaLeqHO6+k6A2ETvvp2LmW0IQtAOaKIukkIIgwty9lGDPdmz41lpgRCOTrgcGN2jHH0LQjFQ/u5jXW4DdwDHu3jt89HL3HuFyq9z9encfDnwOuM7MzmimqIMbLHd9zPAs4KvA5cAT7r6niXlsIGiWaGyejX2H9UC+meU1WHbdd95JEHZ1ClpZ7lg/Dpc93t17Enwfa2LahjY0spzmps03s9hyx352LUGNoHfMo7u7397acoTL6Ntg3uc2mHeuuzf1G5IUUhBEiJkVm9n1ZlYYDg8GLiNouwX4H+AGMzveAiPN7Cigbs/7u2aWHXYgfg54tLHlhDWH/wbuNrP+4bKONLNp4evzw3kbQRt1Tfhoyo1m1ics7zXAYzHjfgdcTLDx/G0z83gcuCYsR2+CZpAmuftaYD7wYzPLNbPxwNeB34eTLCboxM43swKCNvCGvmVmhWGn6PcblDtWHkH7eoWZHQnc2FzZGvleXzOzMeHG95ZmvtNqguazW82si5mdSPB3rPMw8Dkzm2ZB53pu2Ale2OgMD/YEcL4Fhyd3IWj+i92+PAD8KPw9YWb9zOzCVnxPSSIFQbRUEbSrv2nB0T1vEHRoXg/g7n8EfkTQ4VgF/BnId/d9wAUEHcxbCDpQ/ymsUTTlJoLmnzfC5o6XgKJw3KhweAdB5+Uv3X1uM/N6GlhEsPF9DvhN3Qh3LwPeJtibfLWZefw3MBt4F3gH+CtBe3lzAXQZQfv1euAp4BZ3fzEc9ztgCUH7/Wwa38j/IRz3Ufj4r0amAfgP4DiCDvfngCebKdNB3P1vBE17LxOs75aOuPkKQX/N1rA8jxEePhyG34UEoVVOsBd/I3FsJ9z9A+BbBN95A7CdoB+qzr0EzXazzayK4Ld3QjzfUZLP3FUbk/bNzB4E1rv7v7fiM+cSdLgelaQyrSI4uumlZMw/UczsMaDU3ZusSUjHpxqBtGtmNhT4PDG1hCam62pm55lZ57D55RaCvfxIMbNJ4XkLnczsHIIawJ/TXS5Jr6QGgZl9x4KTj943s0fCNsdhZvammS0PT4zpkswySMdlZv9J0LT1E3f/uKXJCZpgthM0DZUQHPIYNQUEh4HuAO4DrnL3d9JaIkm7pDUNhXtdrwFj3H23mT1O0C57HvCkuz9qZg8AS9z9V0kphIiItCjZTUOdga4WnMbfjaAT6XSCIwwgOPTvoiSXQUREmpG0i865+zozu4vgtP3dBEdPLAIq/MAFpcpo4gQdM5sBzADo3r378cXFxckqqohIh7Ro0aIt7n7ItbcaSloQmFkfgo6oYUAF8EeCww8barRtyt1nAjMBJk6c6AsXLkxSSUVEOiYza+5M83rJbBo6k+DaMuXuvp/g2OiTgN5hUxEEZ3o2dbaliIikQDKDYA3waTPrFp5BegbB1R9fAb4YTnMFwclCIiKSJkkLgvCCYE8QnPX5XrismQRnnF5nZisIrkXS7PHfIiKSXEm9Q1l4tmLDMxY/AiYnc7ki0nHs37+fsrIy9uxp6nqCkpubS2FhIdnZ2W36vG5VKSIZraysjLy8PIYOHUrQyiyx3J2tW7dSVlbGsGHD2jQPXWJCRDLanj176Nu3r0KgCWZG3759D6vGpCAQkYynEGje4a4fBYGISMQpCEREWmBmXH755fXD1dXV9OvXj/PPPz+NpUocBYGISAu6d+/O+++/z+7duwF48cUXOfLI1ty+OrMpCERE4nDuuefy3HPPAfDII49w2WWX1Y/buXMn06dPZ9KkSXzqU5/i6aeD82QfeughPv/5z3POOecwatQovvvd76al7C3R4aMi0m78x18+4MP1lQmd55hBPbnlc8e0ON2XvvQlbrvtNs4//3zeffddpk+fzquvBndH/dGPfsTpp5/Ogw8+SEVFBZMnT+bMM88EYPHixbzzzjvk5ORQVFTE1VdfzeDBgxP6HQ6XgkBEJA7jx49n1apVPPLII5x33nkHjZs9ezbPPPMMd911FxAc8rpmzRoAzjjjDHr16gXAmDFjWL16tYJARKSt4tlzT6YLLriAG264gblz57J169b6992dP/3pTxQVFR00/ZtvvklOTk79cFZWFtXV1WQa9RGIiMRp+vTp/PCHP2TcuHEHvT9t2jR+/vOfU3fHx3feaV93/1QQiIjEqbCwkGuuueaQ93/wgx+wf/9+xo8fz9ixY/nBD36QhtK1XdLuWZxIujGNSHSVlJRw9NFHp7sYGa+x9WRmi9x9YkufVY1ARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiLmlBYGZFZrY45lFpZteaWb6ZvWhmy8PnPskqg4iItCyZN69f6u4T3H0CcDywC3gKuBmY4+6jgDnhsIhIRvrOd77DPffcUz88bdo0rrzyyvrh66+/np/97GfpKFrCpKpp6AxgpbuvBi4EZoXvzwIuSlEZRERa7aSTTmL+/PkA1NbWsmXLFj744IP68fPnz2fKlCnpKl5CpCoIvgQ8Er4e4O4bAMLn/ikqg4hIq02ZMqU+CD744APGjh1LXl4e27dvZ+/evZSUlDBhwgRuvPFGxo4dy7hx43jssccAmDt3LqeddhqXXnopo0eP5uabb+b3v/89kydPZty4caxcuRKA8vJyvvCFLzBp0iQmTZrE66+/DsCtt97K9OnTmTp1KsOHD+e+++5LyndM+kXnzKwLcAHwvVZ+bgYwA2DIkCFJKJmItDt/uxk2vpfYeRaMg3Nvb3L0oEGD6Ny5M2vWrGH+/PmceOKJrFu3jgULFtCrVy/Gjx/Ps88+y+LFi1myZAlbtmxh0qRJnHrqqQAsWbKEkpIS8vPzGT58OFdeeSX/+Mc/uPfee/n5z3/OPffcwzXXXMN3vvMdTj75ZNasWcO0adMoKSkBoLS0lFdeeYWqqiqKioq46qqryM7OTugqSMXVR88F3nb3TeHwJjMb6O4bzGwgsLmxD7n7TGAmBJeYSEE5RUQaVVcrmD9/Ptdddx3r1q1j/vz59OrVi5NOOonXXnuNyy67jKysLAYMGMBpp53GW2+9Rc+ePZk0aRIDBw4EYMSIEZx99tkAjBs3jldeeQWAl156iQ8//LB+eZWVlVRVVQHw2c9+lpycHHJycujfvz+bNm2isLAwod8vFUFwGQeahQCeAa4Abg+fn05BGUSkI2hmzz2Z6voJ3nvvPcaOHcvgwYP56U9/Ss+ePZk+fTpz5sxp8rOxl6Hu1KlT/XCnTp3qL0ldW1vLggUL6Nq1a7OfT9ZlrJPaR2Bm3YCzgCdj3r4dOMvMlofj0vOXFRGJ05QpU3j22WfJz88nKyuL/Px8KioqWLBgASeeeCKnnnoqjz32GDU1NZSXlzNv3jwmT54c9/zPPvtsfvGLX9QPL168OBlfo0lJDQJ33+Xufd39k5j3trr7Ge4+KnzelswyiIgcrnHjxrFlyxY+/elPH/Rer169OOKII7j44osZP348xx57LKeffjp33nknBQUFcc//vvvuY+HChYwfP54xY8bwwAMPJONrNEmXoRaRjKbLUMdHl6EWEZE2UxCIiEScgkBEMl57aMJOp8NdPwoCEcloubm5bN26VWHQBHdn69at5ObmtnkeqTiPQESkzQoLCykrK6O8vDzdRclYubm5h3WSmYJARDJadnY2w4YNS3cxOjQ1DYmIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJuGTfvL63mT1hZqVmVmJmJ5pZvpm9aGbLw+c+ySyDiIg0L9k1gnuB5929GDgWKAFuBua4+yhgTjgsIiJpkrQgMLOewKnAbwDcfZ+7VwAXArPCyWYBFyWrDCIi0rJk1giGA+XA/5rZO2b2P2bWHRjg7hsAwuf+jX3YzGaY2UIzW6gbUoiIJE8yg6AzcBzwK3f/FLCTVjQDuftMd5/o7hP79euXrDKKiEReMoOgDChz9zfD4ScIgmGTmQ0ECJ83J7EMIiLSgqQFgbtvBNaaWVH41hnAh8AzwBXhe1cATyerDCIi0rJk37P4auD3ZtYF+Aj4Z4LwedzMvg6sAS5JchlERKQZSQ0Cd18MTGxk1BnJXK6IiMRPZxaLiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4pJ6q0ozWwVUATVAtbtPNLN84DFgKLAKuNTdtyezHCIi0rRU1Ag+4+4T3L3u3sU3A3PcfRQwJxwWEZE0SUfT0IXArPD1LOCiNJRBRERCyQ4CB2ab2SIzmxG+N8DdNwCEz/0b+6CZzTCzhWa2sLy8PMnFFBGJrqT2EQBT3H29mfUHXjSz0ng/6O4zgZkAEydO9GQVUEQk6pJaI3D39eHzZuApYDKwycwGAoTPm5NZBhERaV7SgsDMuptZXt1r4GzgfeAZ4IpwsiuAp5NVBhERaVkym4YGAE+ZWd1y/uDuz5vZW8DjZvZ1YA1wSRLLICIiLUhaELj7R8Cxjby/FTgjWcsVEZHW0ZnFIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOLiCgIzuyTmchH/bmZPmtlxyS2aiIikQrw1gh+4e5WZnQxMI7iPwK+SVywREUmVeIOgJnz+LPArd38a6JKcIomISCrFGwTrzOzXwKXAX80spxWfFRGRDBbvxvxS4AXgHHevAPKBG5NWKhERSZm4gsDddxHcQObk8K1qYHmyCiUiIqkT71FDtwA3Ad8L38oGHk5WoUREJHXibRq6GLgA2An1t6DMS1ahREQkdeINgn3u7oBD/a0nRUSkA4g3CB4PjxrqbWbfAF4C/jt5xRIRkVSJ61aV7n6XmZ0FVAJFwA/d/cV4PmtmWcBCYJ27n29mw4BHCY48ehu43N33tan0IiJy2FqsEZhZlpm95O4vuvuN7n5DvCEQugYoiRm+A7jb3UcB24Gvt67IIiKSSC0GgbvXALvMrFdrZ25mhQRnI/9POGzA6cAT4SSzgItaO18REUmcuJqGgD3Ae2b2IuGRQwDu/m8tfO4e4LscOMKoL1Dh7tXhcBlwZGMfNLMZwAyAIUOGxFlMERFprXiD4LnwETczOx/Y7O6LzGxq3duNTOqNfd7dZwIzASZOnNjoNCIicvji7SyeZWZdgNHhW0vdfX8LH5sCXGBm5wG5QE+CGkJvM+sc1goKgfVtK7qIiCRCvGcWTyW4pMT9wC+BZWZ2anOfcffvuXuhuw8FvgS87O5fAV4BvhhOdgXwdNuKLiIiiRDveQQ/Bc5299Pc/VSCexLc3cZl3gRcZ2YrCPoMftPG+YiISALE20eQ7e5L6wbcfZmZZce7EHefC8wNX38ETG5FGUVEJIniDYKFZvYb4Hfh8FeARckpkoiIpFK8QXAV8C3g3wiO/JlH0FcgIiLtXLxB0Bm4191/BvWXjchJWqlERCRl4u0sngN0jRnuSnDhORERaefiDYJcd99RNxC+7pacIomISCrFGwQ7zey4ugEzmwjsTk6RREQkleLtI7gW+KOZrSe4JMQg4P8krVSSFu7Ovppacjpnpbso0gG5O3ura8nN1u8r0zQbBGY2CVjr7m+ZWTHwL8DngeeBj1NQPkkBd2f2h5u464WlrCjfwbC+3SkemEfRgJ4UD8zj6IKeFPbpSqdOjV0qSuRQlXv2s3RjFaUbqyjdUEnpxiqWbqxi175qJgzuzdSi/kwt6sfYQb30u8oAFtyBsomRZm8DZ7r7tvCSEo8CVwMTgKPd/YtNfjiBJk6c6AsXLkzFoiLnHx9v4/a/lfD2mgqG9+vOuWML+Kh8J6Ubq1i1dSd1P4/uXbIYXZBHcUFPjh6YR9GA4HWvbnGfVygdUHVNLau27qRkQxWlGytZurGKkg1VrKs40HLcM7czxQN7cnRBHj1yO/Paiq28W1aBOxzRowunjurHaUX9OHVUP/p075LGb9PxmNkid5/Y4nQtBMESdz82fH0/UO7ut4bDi919QoLK2ywFQeKVbqzkzueX8nLpZgb0zOHaM0dzyfGFdM460G20a181yzbtYOnGyvp/9NKNVVTsOnC9wUG9cike2JOigjyKC/I4emBPhh3RneyseLuf2pHqvbBrG+zefuCR0wOGnQbW8fdqy6v2HrSxL91YyfLNO9hXXQtA507GiH49gtpkQVCTLB6YR0HPXKzB+tm6Yy/zlpczd2k585aVs33XfjoZqi0kWKKC4H1ggrtXm1kpMMPd59WNc/exCStxMxQEibN22y7ufnEZTy1eR15OZ66aOpKvnTSUrl3ia7d1dzZX7aUkrO7XVftXlu9gf03wW+qS1YkR/XtwdEFeuFEI9gb75eUcskFIi8Y26Ltjhg8aV3Fg3P5djc+vYBxM/R4UndchAmHP/hpWbN5R/zcOmngq2bLjwB1l++fl1O/l1zUjjujfvU39SzW1zrtlFbyytJy/L93Mu+s+UW0hQRIVBP8XOA/YAgwBjnN3N7ORwCx3n5KoAjdHQXD4tu3cxy9eXsHDb6zGDL520lCumjqC3t0S88+1r7qWj7bsoHRD2C68sZLSDVVsrNxTP01+9y5Bk9LAA3uLo/rnxR1Chzhkg95g437Ixn578xt0gE6doWs+dO0D3cLnxh514zZ9CPPuhG0ftbtAcHfKtu8ON/aVlITB/vGWndSGm4Xc7E71zYBF4Ua/uKAn+UncKKu2kDgJCYJwRp8GBgKz3X1n+N5ooIe7v52IwrZEQdB2O/dW85vXPmbmvI/Yta+aS44fzLVnjWJgr64tfzgBKnbtO6jmULeHuXt/DRBsL0fnd+G4/rUc07uW0b2qGdZtL32zdtJpT8VhbNCzD91oN7dB79onCIAu3Vu/Ea+phvf+mNGBULlnP8s2VtVv7JeGf4eqvdX10wzJ70ZxQV79nn5RQR5H9e1OVho3uM3WFkb3Y2pRf04ddUTCdmg6moQFQSZQELTe/ppaHv3HGu6ds4ItO/Yy7ZgB3DitiJH981r+cJsXuieu5hbfvZ39VVup2bWNznsryK7d0+Qsq60z+7N74V3z6ZLXl87dG9moH7Khb+MG/XBlQCDEdt7WNek01XlbHHb+Fw/MY/SAPHrkxHs0efqottA6CoKIqq11nn1vAz+dvZTVW3cxeVg+N59bzHFD+sQ/kzg36G3aQ29m73xvl96s3ZPDispsSiqyWLy1E0s27adi94G91nbROZ2iQCiv2nvQxr6xztvh/brXb+yPDpt3BvY6tPO2PVJtoWUKgohxd15dvoU7ni/lg/WVFBfkcdM5xUwt6tf8P/2eSljzBqx6FVa9BuWlbdig50PX3k03t3Tt0+Y9dHdnU+VeSsKjVeLpnC4uCPZ20945naBAaE3nbXEYkMUFbe+8ba9iawt/X1ZOhWoLCoIoWbK2gjueL2X+yq0U9unK9WeP5sJjj2z8B99ww79hMXgtZHWBwkkwcMKBDXkCN+iJFts5fSAkDu2cLi44+FDGw+qcbqs4A6Gu87Z+L7+JztvRAw5s7Ou+X98euhhwrJpaZ0lZRRAKEa4tKAgi4KPyHfx09jKee28D+d27cPXpI/nyCUMO3gtsacM/9OTgUTgJslPTgZxM23fuqz8KpjTsHF3WoHO67szpuiNhUnbmdINA2JU/hjeP+hdeqjmOpZt2NN15G3bgFmdA5217FdXaQtqDwMxyCW5gk0NwKYsn3P0WMxtGcIZyPvA2cLm772t6TgqChjZX7uGeOct57K215HTuxJWnDOcbpwwjLzc7chv+eNTWOmu27apvS6/b4169bddBZ04XFYTnPMSERK+uh3fmdGOdt8vWVzCx6iWu7vwUwzptooSh/KX3FewYehbFA3uF5WgfnbftUZRqC5kQBAZ0d/cd4f2NXwOuAa4DnnT3R83sAWCJu/+quXkpCAKf7N7Pr/++kgdf/5iaWufLk4dw9ZQCjtj2tjb8bbBzbzXLNlXVXxOnrg3+k92Hnjld38TUTOf0lh17w/MowsDZVMmyTQc6b7M6GSPCztuigjzGDOjKhIqX6L3wHixDDzuNgo5cW0h7EDQoTDeCILgKeA4oCM9WPhG41d2nNff5qAfBnv01/HbBKn45dyXVuz7h6pFbuKz/GnpufEMb/gSL7Zwujbl+zorNO6iuPbRzule3bJZv2nFI522/vJz6o5rqQmRk/x6Nd95mwGGnEuhotYWMCILwlpaLgJHA/cBPgDfcfWQ4fjDwt8YuVWFmM4AZAEOGDDl+9erVSStnpqqpdZ5+s5TX5/yFUXuWcFa35QzfvxzThj/l9lXXsrI8aMePDYmKXfuDppwBB5+I1abOWwVCxtmyYy/zloXnLSw/tLbwmaL+HDOoZ8bWFjIiCGIK0xt4Cvgh8L8NguCv7j6uuc9HqkawpxJfs4BVi15g7/J5jKpZQZY5tZ260GmwNvyRoEDISO2xtpBRQQBgZrcAu4CbUNPQAQ06d33DYsxr2eudKc0qolvRaYycdA42eLI2/FGjQMho7aG2kPYgMLN+wH53rzCzrsBs4A7gCuBPMZ3F77r7L5ubV4cKgiaO6qnt1IXl2cU8v3MkpTnjmXrGZ/nCCSMPuiy0RJQCIeNlam0hE4JgPDALyCK4N/Lj7n6bmQ3nwOGj7wBfdfe9zc2rXQdBC4dzVg44gYc3Dea+ZX3IzunGVVNH8M8nDUv9SU+S+RQI7Uam1BbSHgSJ1K6CIM7j+Lf1OZZfvLqOh99YDQb/nODLQksHpkBoV9JZW1AQpEorT+Data+a37z6Mb8OLwv9xeMLufbM0QzqrfZ/aSUFQruUytqCgiBZ2njmbsPLQp89Jrgs9KgBSbwstESDAqHdiq0tzF26mXfLPgEOri2cXty/zWeZKwgS5TAv2dDYZaFvOqeY449qxWWhReKhQGj3GqstvHTdqW2+j4iCoK0SeK2eV5eXc8fzpby/rhWXhRY5XAqEDqGm1nl/3SeML+zV5m2GgiBeSbhI27tlwWWhX1+xlSN7h5eFnnCkrhopqaVAiDwFQVOSeHXOj7fs5K4XltZfFvrbnxnJVz49JFI3B5EMpECILAVBnRRclnlz5R7unbOcR+suC33yML5x6vDgstAimUKB0P7UbZ/VNHQYQfCnb8D7TyTt6pyVe8LLQr+2iv01tXz5hCFcffoo+uXpblGSwRQImWnvjuBWsZveh00fHHj86xvQc2CbZhlvEHTsO18UToT8YQm/SNue/TX8bsFq7p+7gopd+7ng2EFcf/YZ7TsnAAAJi0lEQVRojurbPSHzF0mqrM4w4TIYd8mBQHj0ywqEVKmtge2rDt3gb//4wDRdekD/MXDMxVBb3eSsEqVj1wgSrKbWefLtMu5+cRnrP9nDKaOO4KZzihl7ZK90F02k7VRDSJ5d28IN/ocHNvybS6B6dzDeOkH+CBhwzMGPXkOg0+FfZ0xNQwnk7rxUspmfvFDKsk07OLawFzedU8xJI49IW5lEEk6B0HbV+2DLsnDv/n3Y/GHwumrDgWm69Q039GOD5/5joF8xdOmWtGIpCBLkrVXbuONvpSxcvZ3hR3TnhmlFnDu2QOcCSMelQGiaO1SuD/fsY5p1tiw70IST1QX6FQUb/P5jDmz8e/RP+fpTEBympRuruPP5UuaUbqZ/Xg7XnjmaSyYWNnqvWpEOKeqB0FTn7Z6KA9P0GhyzsQ8ffUdCVmYcMaggaKOy7bv42YvLeOqddfTI6cw3TxvB9Cm6LLREWEcPhNZ03sZu8PuPga6901bseCgIWmnbzn3c/8oKfrcguCz0104aylWnjaBPd10WWgToGIHQWOdteSns3xWMt06QP/zQtvzeRyWk8zbVFARxqrss9Mx5H7FTl4UWaVl7CIR4Om+75kPB2IPb8pPceZtqOo+gBftrann0rbXcN2c55VV7OWvMAL6ry0KLtCyTzkNoTeftsNMObtrpMSBzgivNIlcjqK11ngsvC71q6y4mD83npnOLOP6o/ITMXyRyUlVDiKfztmfhocfkZ1DnbaqlvWnIzAYDvwUKgFpgprvfa2b5wGPAUGAVcKm7b29uXokKgteWb+H250t4f10lRQPyuOncIj5T1F+HgookQqICoVWdt2Ni2vKPhq66z0esTAiCgcBAd3/bzPKARcBFwNeAbe5+u5ndDPRx95uam9fhBsF7ZZ9wx/OlvLZiC0f27sp1Z43mok/pstAiSdGaQGip8xaDviMOdN7WteW3087bVEt7EByyILOngV+Ej6nuviEMi7nuXtTcZ9saBB9v2clds5fy3Lsb6NMtm2+fPoqv6rLQIqnRWCB86p/gk7XNd972j2nW6WCdt6mWUUFgZkOBecBYYI27944Zt93dD6nPmdkMYAbAkCFDjl+9enWrl3vpAwt4b90nXHlKcFnonrostEjqNQyErC5wRFFMO37YvKPO24TLmCAwsx7A34EfufuTZlYRTxDEamuNYMXmKnp2zaZ/Xm6rPysiCVZTDZ+sCc7GjWjnbaplxOGjZpYN/An4vbs/Gb69ycwGxjQNbU7W8tt6w2cRSYKszsHJWpJxktbbYsGhOL8BStz9ZzGjngGuCF9fATydrDKIiEjLklkjmAJcDrxnZovD974P3A48bmZfB9YAlySxDCIi0oKkBYG7vwY01fNzRrKWKyIiraMDcUVEIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxybx5/YNmttnM3o95L9/MXjSz5eFzn2QtX0RE4pPMGsFDwDkN3rsZmOPuo4A54bCIiKRR0oLA3ecB2xq8fSEwK3w9C7goWcsXEZH4pLqPYIC7bwAIn/unePkiItJAxnYWm9kMM1toZgvLy8vTXRwRkQ4r1UGwycwGAoTPm5ua0N1nuvtEd5/Yr1+/lBVQRCRqUh0EzwBXhK+vAJ5O8fJFRKSBZB4++giwACgyszIz+zpwO3CWmS0HzgqHRUQkjTona8buflkTo85I1jJFRKT1MrazWEREUkNBICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxCgIRkYhLSxCY2TlmttTMVpjZzekog4iIBFIeBGaWBdwPnAuMAS4zszGpLoeIiATSUSOYDKxw94/cfR/wKHBhGsohIiJA5zQs80hgbcxwGXBCw4nMbAYwIxzcYWZL27i8I4AtbfxsFGl9tY7WV+tofbXO4a6vo+KZKB1BYI2854e84T4TmHnYCzNb6O4TD3c+UaH11TpaX62j9dU6qVpf6WgaKgMGxwwXAuvTUA4RESE9QfAWMMrMhplZF+BLwDNpKIeIiJCGpiF3rzazbwMvAFnAg+7+QRIXedjNSxGj9dU6Wl+to/XVOilZX+Z+SPO8iIhEiM4sFhGJOAWBiEjEdZggMLMBZvYHM/vIzBaZ2QIzu9jM+prZK2a2w8x+ke5yZpJm1tlZ4fB74fPp6S5rJmhmfU02s8XhY4mZXZzusmaCptZXzPgh4f/lDeksZ6Zo5vc11Mx2x/zGHkj0stNxHkHCmZkBfwZmufuXw/eOAi4A9gA/AMaGD6HFdfYa8Dl3X29mYwk69o9MW2EzQAvr6wVgYnggxEBgiZn9xd2r01fi9GphfdW5G/hbGoqXcVpYX+8AK919QrKW3yGCADgd2Ofu9Unp7quBn4eDr5nZyLSULHO1tM7qfADkmlmOu+9NZQEzTLzrK5dGTpCMoGbXl5ldBHwE7ExP8TJOk+vLzIYme+EdpWnoGODtdBeinYl3nX0BeCfiIQAtrC8zO8HMPgDeA74Z5dpAqMn1ZWbdgZuA/0hpiTJbS/+Pw8zsHTP7u5mdkuiFd5QawUHM7H7gZIKEnZTu8rQHja0zMzsGuAM4O51ly0QN15e7vwkcY2ZHA7PM7G/uvie9pcwcsesL+Dtwt7vvCFpEpKEG6+tkYIi7bzWz44E/m9kx7l6ZqOV1lBrBB8BxdQPu/i3gDKBf2kqU+ZpdZ2ZWCDwF/JO7r0xLCTNLXL8xdy8haO6Ien9Uc+vrBOBOM1sFXAt8PzzJNMqaXF/uvtfdt4bvLwJWAqMTufCOEgQvE7RjXxXzXrd0FaadaHKdmVlv4Dnge+7+ejoKl4GaW1/DzKxz+PoooAhYlfISZpYm15e7n+LuQ919KHAP8P/cPepH9DX3++oX3scFMxsOjCLoX0mYDnNmcXi0xt0EexvlBHtlD7j7Y+GeR0+gC1ABnO3uH6arrJmiqXVG8EP7HrA8ZvKz3X1zyguZQZpZX12Am4H9QC1wm7v/OV3lzBTN/U/GTHMrsMPd70pLITNIM7+vauC28LkGuMXd/5LQZXeUIBARkbbpKE1DIiLSRgoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjE/X+sDpwPhPuKfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n\\ndata = {'apples': 10, 'oranges': 15, 'lemons': 5, 'limes': 20}\\nnames = list(data.keys())\\nvalues = list(data.values())\\n\\nfig, axs = plt.subplots(1, 3, figsize=(9, 3), sharey=True)\\naxs[0].bar(names, values)\\naxs[1].scatter(names, values)\\naxs[2].plot(names, values)\\nfig.suptitle('Categorical Plotting')\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "N = 5\n",
    "menMeans = (20, 35, 30, 35, 27)\n",
    "womenMeans = (25, 32, 34, 20, 25)\n",
    "# menStd = (2, 3, 4, 1, 2)\n",
    "# womenStd = (3, 5, 2, 3, 3)\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.1       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.plot(ind, menMeans)\n",
    "p2 = plt.plot(ind, womenMeans)\n",
    "\n",
    "\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores by group and gender')\n",
    "plt.xticks(ind, ('G1', 'G2', 'G3', 'G4', 'G5'))\n",
    "plt.yticks(np.arange(0, 81, 10))\n",
    "plt.legend((p1[0], p2[0]), ('Men', 'Women'))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {'apples': 10, 'oranges': 15, 'lemons': 5, 'limes': 20}\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(9, 3), sharey=True)\n",
    "axs[0].bar(names, values)\n",
    "axs[1].scatter(names, values)\n",
    "axs[2].plot(names, values)\n",
    "fig.suptitle('Categorical Plotting')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "\n",
    "closed cat: \n",
    "\n",
    "# fast text\n",
    "# prepare: 30% \n",
    "recall   :  0.5285323159148717\n",
    "precision:  0.7667236277154985\n",
    "F1:  0.6257268559406325\n",
    "\n",
    "# fast text\n",
    "# prepare: 40% \n",
    "recall   :  0.6653763412156922\n",
    "precision:  0.6560469590605652\n",
    "F1:  0.6606787169473115\n",
    "\n",
    "# fast text\n",
    "# prepare: 50% \n",
    "recall   :  0.7307203513937793\n",
    "precision:  0.5442378845785564\n",
    "F1:  0.6238411377573608\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# glove\n",
    "# prepare: 30% \n",
    "recall   :  0.5901447235808291\n",
    "precision:  0.6935508181135666\n",
    "F1:  0.6376829124211885\n",
    "\n",
    "# prepare: 40% \n",
    "recall   :  0.6806225808749135\n",
    "precision:  0.5790998736466896\n",
    "F1:  0.6557703022931815\n",
    "\n",
    "\n",
    "# prepare: 50% \n",
    "recall   :  0.7486203116844091\n",
    "precision:  0.5628899222525487\n",
    "F1:  0.6426039509821643\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# word2vec\n",
    "# prepare: 30% \n",
    "recall   :  0.5081466692424097\n",
    "precision:  0.7211979639471998\n",
    "F1:  0.5962109132787884\n",
    "\n",
    "voc = 20000\n",
    "# prepare: 40% \n",
    "recall   :  0.6317289653025961\n",
    "precision:  0.6881530234925131\n",
    "F1:  0.6587349493232045\n",
    "\n",
    "voc = 20000\n",
    "# prepare: 50% \n",
    "recall   :  0.6784845959839875\n",
    "precision:  0.6082674972803995\n",
    "F1:  0.6414601993698661\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "voc = 20000\n",
    "# prepare: 60% \n",
    "recall   :  0.721041913777005\n",
    "precision:  0.595738371819323\n",
    "F1:  0.6524282606987408\n",
    "\n",
    "\n",
    "voc = 20000\n",
    "# prepare: 50% \n",
    "recall   :  0.6784845959839875\n",
    "precision:  0.6082674972803995\n",
    "F1:  0.6414601993698661\n",
    "\n",
    "\n",
    "voc = 20000\n",
    "# prepare: 40% \n",
    "recall   :  0.6317289653025961\n",
    "precision:  0.6881530234925131\n",
    "F1:  0.6587349493232045\n",
    "\n",
    "\n",
    "voc = 20000\n",
    "normalization true\n",
    "# prepare: 30% \n",
    "recall   :  0.5081466692424097\n",
    "precision:  0.7211979639471998\n",
    "F1:  0.5962109132787884\n",
    "\n",
    "\n",
    "# prepare: 20% \n",
    "recall   :  0.3344593858999539\n",
    "precision:  0.805725002588478\n",
    "F1:  0.47269949017147983\n",
    "\n",
    "# prepare: 10% \n",
    "recall   :  0.195086903420372\n",
    "precision:  0.860476656631505\n",
    "F1:  0.3180627538895051\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "voc = 25000\n",
    "normalization true\n",
    "# prepare: 30% \n",
    "Overall results:\n",
    "recall   :  0.5085084366313575\n",
    "precision:  0.7393061549882609\n",
    "F1:  0.6025629441903858\n",
    "\n",
    "\n",
    "\n",
    "voc = 30000\n",
    "Overall results:\n",
    "# prepare: 30% \n",
    "recall   :  0.4847320654403819\n",
    "precision:  0.7464213664098622\n",
    "F1:  0.5877648736030088\n",
    "\n",
    "\n",
    "voc = 15000\n",
    "normalization true\n",
    "# prepare: 30% \n",
    "recall   :  0.42876176111470227\n",
    "precision:  0.8377619006386419\n",
    "F1:  0.56722235637565\n",
    "\n",
    "voc = 10000\n",
    "normalization true\n",
    "# prepare: 30% \n",
    "recall   :  0.3729067481988374\n",
    "precision:  0.8512218188235888\n",
    "F1:  0.5186160490078476\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "voc = 15000\n",
    "normalization true\n",
    "# prepare: 40% \n",
    "recall   :  0.5355245995834231\n",
    "precision:  0.8011979544196943\n",
    "F1:  0.6419600124838828\n",
    "\n",
    "voc = 10000\n",
    "normalization false\n",
    "# prepare: 30% \n",
    "recall   :  0.42950154338186797\n",
    "precision:  0.6340399400356664\n",
    "F1:  0.5121025123270261\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "voc = 5000\n",
    "recall upper bound:  0.7239558953554897\n",
    "recall   :  0.24043199270866614\n",
    "precision:  0.6938998515673223\n",
    "F1:  0.35712306087963763\n",
    "\n",
    "voc = 10000\n",
    "recall upper bound:  0.8438102668122951\n",
    "recall   :  0.3720777755487695\n",
    "precision:  0.6253987131442225\n",
    "F1:  0.46657132204222984\n",
    "\n",
    "voc_size = 15000\n",
    "recall upper bound:   0.9176971966505436\n",
    "recall   :  0.39971054543833456\n",
    "precision:  0.5097319170941914\n",
    "F1:  0.44806621859656187\n",
    "\n",
    "voc_size = 20000\n",
    "recall upper bound:  0.9473016071149946\n",
    "# prepare: 20% \n",
    "recall   :  0.41560240237562746\n",
    "precision:  0.3414888425269251\n",
    "F1:  0.374918041370112\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "google corpus\n",
    "\n",
    "voc = 10000\n",
    "\n",
    "# prepare: 20% \n",
    "recall   :  0.36396917443694177\n",
    "precision:  0.31804197362403475\n",
    "F1:  0.3394591859835288\n",
    "\n",
    "# prepare: 30% \n",
    "Overall results:\n",
    "recall   :  0.498205148720756\n",
    "precision:  0.23708784389356125\n",
    "F1:  0.3212824974896275\n",
    "\n",
    "# prepare: 40% \n",
    "recall   :  0.5562604281309145\n",
    "precision:  0.19870262554060306\n",
    "F1:  0.29281011041910965\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "for cat in closed_cats:\n",
    "    print(cat)\n",
    "    print(len(cat))\n",
    "'''\n",
    "\n",
    "'''   \n",
    "path = r\"/home/hanselowski/jupiter_projects/vecSpace_decomp/datasets/closed_cat_corpus.txt\"\n",
    "with open(path) as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip() for x in content] \n",
    "\n",
    "closed_cats, set = [], []\n",
    "for row in content:\n",
    "    if \":\" in row and len(set) > 0: \n",
    "        closed_cats.append(set)\n",
    "        print(set)\n",
    "        set = []\n",
    "    elif \":\" not in row:\n",
    "        set.append(row.lower())\n",
    "    cur_entry = row[0]\n",
    "closed_cats.append(set)\n",
    "''' \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
